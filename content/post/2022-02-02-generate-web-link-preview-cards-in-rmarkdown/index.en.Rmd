---
title: Generate Web Link Preview Cards in Rmarkdown
author: Matt Johnson
date: '2022-02-02'
slug: generate-web-link-preview-cards-in-rmarkdown
categories:
  - web
  - R
tags:
  - rmarkdown
  - htmltools
  - webscape
  - metadata
description: |
  Have you ever noticed those fancy website previews that popup in some platforms like 
  twitter or slack when you include a link. How does the platform know exactly what 
  to display?
featured: ''
featuredalt: ''
featuredpath: ''
linktitle: ''
---

```{r}

```

Recently I was creating a list of R resources and thought it might be interesting to replicate this website preview behavior. If I am honest though, a list of just URL's is neither interesting nor informative. And I did not want to spend all day looking up extra information about each resource.

Most modern websites include a large amount of metadata information embedded in the `<head></head>` tag. Where this metadata complies with the [Open Graph Protocol](https://ogp.me/) it is used to generate website previews and turns websites into data rich documents. For example if you right-click on this page select "inspect", you will find the following html `<meta>` tags:

```html

<meta property='og:title' content='Generate Web Link Preview Cards in Rmarkdown'>
<meta property='og:description' content='Have you ever noticed those fancy website previews that popup in some platforms like 
twitter or slack when you include a link. How does the platform know exactly what 
to display?
'>
<meta property='og:site_name' content='Restless Data'>
<meta property='og:type' content='article'>
<meta property='article:section' content='Post' />
<meta property='article:tag' content='rmarkdown' />
<meta property='article:tag' content='htmltools' />
<meta property='article:tag' content='webscape' />

```

To use this data for our own previews within an rmarkdown document we will need to do a little web-scraping and generate some html. Lets start with the web-scraping.

The [rvest package](https://rvest.tidyverse.org/) makes it really easy to import the content of a webpage simply using `read_html()`. However, in this case we only need the metadata so there is no need to read the entire page. So I opted to use the `readLines()` function as it can limit the number of lines read in. Let's use the [Open Graph Protocol](https://ogp.me/) website as an example:

```{r read lines}

doc <- readLines('https://ogp.me/', n = 21)
doc

```
Notice with `n = 21` we get the entire header including all the metadata tags. Now we can use `read_html()` to read the text and parse the tags; we want all of the meta tags plus the title tag. The inclusion of `paste0()` below is for 2 reasons. First, `readLines()` produces a vector and `read_html()` requires character of length 1. Second, remember meta tags above? They carried over multiple lines and so `paste0()` ensures all the tags start and end points line up.

```{r parse}

library(rvest)

nodes <- doc |>
  paste0(collapse = '') |>
  read_html() |>
  html_nodes('meta, title')
nodes[1:7]

```






```{r metadata, echo=TRUE, message=FALSE, warning=FALSE}

library(dplyr)
library(purrr)


read_meta <- function(url, n = -1){
  
  doc <- readLines(url, n = n) |> 
    paste0(collapse = '') # cleans parts of page where tag contents are across multiple rows
  
  nodes <- doc |>
    read_html() |>
    html_nodes('meta, title')
  
  meta_properties <- nodes |>
    map_dfr(~ tibble(property = html_attr(.x, 'property'),
                     content = html_attr(.x, 'content'))) |>
    filter(!is.na(property))
    
  meta_names <- nodes |>
    map_dfr(~ tibble(property = html_attr(.x, 'name'),
                     content = html_attr(.x, 'content'))) |>
    filter(!is.na(property))
  
  meta <- bind_rows(meta_properties, meta_names)
  
  # check for a title tag
  title <- nodes |> html_nodes(xpath = "/html/head/title") |> html_text()
  title_tag <- if ('og:title' %in% meta$property) 'title' else 'og:title'
  
  if (length(title) > 0) {
    meta <- meta |>
      add_row(property = title_tag,
              content = title)
  }
  
  return(meta)
  
}
```


```{r card, echo=TRUE, message=FALSE, warning=FALSE}


library(htmltools)


card_url <- function(metadata){
  
  card_title <- metadata |> filter(property == 'og:title') |> pull(content)
  card_url <- metadata |> filter(property == 'og:url') |> pull(content)
  card_text <- metadata |> filter(property == 'og:description') |> pull(content)
  card_img <- metadata |> filter(property == 'og:image') |> pull(content)
  card_img_alt <- metadata |> filter(property == 'og:image:alt') |> pull(content) # TODO: use title if metadata missing
  
  card_author <- metadata |> 
    filter(property == 'author') |> 
    pull(content) |>
    paste(collapse = '')
  
  # render bootstrap card
  div(class = 'card',
      style = 'margin-bottom:70px; border: 2px solid #e7e7e7; padding: .5rem;',
      div(style = 'display: inline-grid; grid-template-columns: 55% 40%;',
          div(class = 'card-body',
              h4(class = 'card-title',
                 a(href = card_url,
                   card_title)
                 ),
              p(class="card-text text-secondary",
                card_text),
              p(class="card-text text-secondary",
                if (card_author != '') {
                  div("Author(s):", br(), card_author)
                })
            ),
          div(if (length(card_img) > 0) img(class="h-100", src = card_img, alt = card_img_alt) else '')
          )
      )
}
```



```{r render a card}

read_meta('https://restlessdata.com.au') |>
  card_url()

```










